{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.18/04\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_files(file_ch1, file_ch2):\n",
    "    df1 = pd.read_csv(file_ch1,'Channel 1',engine='python')\n",
    "    df2 = pd.read_csv(file_ch2,'Channel 2',engine='python')\n",
    "    res = pd.concat([df1,df2],axis=1)\n",
    "    res.to_csv('merged_channels.dat',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = './Labs/muon_271119/Run3/3052B-01_1_1_113001_2010_191127-175401.dat'\n",
    "file2 = './Labs/muon_271119/Run3/3052B-01_2_2_113002_1410_191127-175401.dat'\n",
    "\n",
    "merge_files(file1, file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = np.genfromtxt('merged_channels.dat',delimiter=',', usecols=[0,1], invalid_raise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000.0\n"
     ]
    }
   ],
   "source": [
    "timestep_in_s = 10*dt[7,0]\n",
    "timestep_in_ns = timestep_in_s*1E9\n",
    "ayy = dt[9,0]\n",
    "no_events = dt[10,0]\n",
    "print(no_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time per event: 200.0 ns\n"
     ]
    }
   ],
   "source": [
    "print(\"Time per event: {time} ns\" .format(time = timestep_in_ns ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_channels = dt[13:]\n",
    "total_size = data_channels[:,0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of point per events 1000\n",
      "Number of events: 1000\n"
     ]
    }
   ],
   "source": [
    "points_per_event = int(round(timestep_in_s/ayy))\n",
    "print('Number of point per events {points}'.format(points=points_per_event))\n",
    "events = total_size//points_per_event\n",
    "print('Number of events: {events}'.format(events=events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 200.0\n",
      "200.0\n"
     ]
    }
   ],
   "source": [
    "time_per_event_in_ns = timestep_in_ns/(points_per_event)\n",
    "print(time_per_event_in_ns,timestep_in_ns)\n",
    "timesteps_in_ns = np.arange(0,timestep_in_ns,time_per_event_in_ns)\n",
    "print(timestep_in_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ROOT.TFile('testing1.root', 'recreate')\n",
    "tree = ROOT.TTree('channels', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ROOT.TBranchElement object (\"timesteps\") at 0x561edf782ce0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch1 = ROOT.std.vector('float')()\n",
    "ch2 = ROOT.std.vector('float')()\n",
    "timesteps = ROOT.std.vector('float')()\n",
    "\n",
    "tree.Branch('ch1', ch1)\n",
    "tree.Branch('ch2', ch2)\n",
    "tree.Branch('timesteps', timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree.SetEntries\n",
    "for i in range(events):\n",
    "    for data in data_channels[int(points_per_event*i):int(points_per_event*(i+1))]:\n",
    "        ch1.push_back(data[0])\n",
    "        ch2.push_back(data[1])    \n",
    "    for i in range(points_per_event):  \n",
    "        timesteps.push_back(timesteps_in_ns[i])\n",
    "    tree.Fill()\n",
    "    ch1.clear()\n",
    "    ch1.shrink_to_fit()\n",
    "    ch2.clear()\n",
    "    ch2.shrink_to_fit()  \n",
    "    timesteps.clear()\n",
    "    timesteps.shrink_to_fit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.Write()\n",
    "f.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = events\n",
    "x_ch1 = np.empty((N,points_per_event))\n",
    "x_ch2 = np.empty((N,points_per_event))\n",
    "for i in range(N):\n",
    "    tempch1 = []\n",
    "    tempch2 = []\n",
    "    for data in data_channels[int(points_per_event*i):int(points_per_event*(i+1))]:\n",
    "        tempch1.append(data[0])\n",
    "        tempch2.append(data[1])        \n",
    "    temp2ch1 = np.asarray(tempch1)\n",
    "    temp2ch2 = np.asarray(tempch2)\n",
    "    x_ch1[i] = np.transpose(temp2ch1)  \n",
    "    x_ch2[i] = np.transpose(temp2ch2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('ch1_values.csv', x_ch1, fmt=\"%1.4f\", delimiter=\",\")\n",
    "# np.savetxt('ch2_values.csv', x_ch2, fmt=\"%1.4f\", delimiter=\",\")\n",
    "np.savetxt('ch1_events_per_col.csv', np.transpose(x_ch1), fmt=\"%1.4f\", delimiter=\",\")\n",
    "np.savetxt('ch2_events_per_col.csv', np.transpose(x_ch2), fmt=\"%1.4f\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readHeaders = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x1 = ROOT.RDF.MakeCsvDataFrame('ch1_values.csv',readHeaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.Snapshot('ch1','ch1RDF.root')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = ROOT.RDF.MakeCsvDataFrame('ch2_values.csv',readHeaders)\n",
    "x2.Snapshot('ch2','ch2RDF.root')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x1 = ROOT.RDF.MakeCsvDataFrame('ch1_events_per_col.csv',readHeaders)\n",
    "x1.Snapshot('ch1','ch1RDF.root')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
